<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Embodied-AI-with-DP-and-LLM</title>
    <link rel="stylesheet" href="styles.css" >
</head>
<body>
    <h1>Embodied-AI-with-DP-and-LLM</h1>
    <p>Abstract</p>
    <p>The development of large language model (LLM)
        and visual language model(VLM) has driven rapid progress
        in embodied artificial intelligence (Embodied AI) technology,
        opening up new avenues for robots to interact with the physical
        world and providing vast space for robots to perform more
        complex manipulation tasks. Moreover, the diffusion policy can
        elegantly handle multimodal action distributions, it's suitable
        for high-dimensional action spaces, and exhibits impressive
        training stability, making it highly suitable for robot control.
        Traditional robot trajectory planning and control methods are
        sensitive to disturbances and have strict hardware require-
        ments, making them difficult to apply in precise robot grasping
        tasks. In addition, it is difficult to ensure the generalization of
        these methods for different task scenarios. To address these
        issues, this article proposes an Embodied AI scheme based on
        the LLM and the diffusion policy. This solution firstly converts
        human natural language instructions into robot manipulation
        subtasks by LLM and then generates safe robot trajectories and
        actions based on the diffusion policy.</p>
    <img src="data/sim_pic.jpg" alt="Franka_pic_1" width="600">
    <video width="600" controls>
        <source src="data/Screencast.webm" type="video/webm">
        Your browser does not support the video tag.
    </video>
</body>
</html>
